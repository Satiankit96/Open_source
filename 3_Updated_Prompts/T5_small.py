import logging
import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer, BartForConditionalGeneration, BartTokenizer
import evaluate

# Scoring Metrics
sacrebleu = evaluate.load("sacrebleu")
bleu = evaluate.load("bleu")
meteor = evaluate.load("meteor")

class SummarizationEvaluator:
    def __init__(self, t5_model_name="t5-large", bart_model_name="facebook/bart-large-cnn"):
        """
        Initialize the T5 and BART models for summarization.
        :param t5_model_name: Name of the T5 model.
        :param bart_model_name: Name of the BART model.
        """
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.t5_model, self.t5_tokenizer = self.load_model_and_tokenizer(t5_model_name)
        self.bart_model, self.bart_tokenizer = self.load_bart_model_and_tokenizer(bart_model_name)

    def load_model_and_tokenizer(self, model_name):
        """
        Load the pre-trained T5 model and tokenizer.
        :param model_name: Name of the model to use for summarization.
        :return: Model and Tokenizer objects.
        """
        try:
            logging.info(f"Loading T5 model {model_name}...")
            tokenizer = T5Tokenizer.from_pretrained(model_name)
            model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)
            model.eval()
            logging.info(f"Model {model_name} loaded successfully.")
            return model, tokenizer
        except Exception as e:
            logging.error(f"Failed to load T5 model: {e}")
            raise RuntimeError("Error loading T5 model or tokenizer.") from e

    def load_bart_model_and_tokenizer(self, model_name):
        """
        Load the pre-trained BART model and tokenizer for generating ground truth summaries.
        :param model_name: Name of the BART model.
        :return: Model and Tokenizer objects.
        """
        try:
            logging.info(f"Loading BART model {model_name}...")
            tokenizer = BartTokenizer.from_pretrained(model_name)
            model = BartForConditionalGeneration.from_pretrained(model_name).to(self.device)
            model.eval()
            logging.info(f"Model {model_name} loaded successfully.")
            return model, tokenizer
        except Exception as e:
            logging.error(f"Failed to load BART model: {e}")
            raise RuntimeError("Error loading BART model or tokenizer.") from e

    def summarize_t5(self, text: str, custom_prompt: str = None, max_length: int = 150, min_length: int = 100) -> str:
        """
        Generate a summary for the provided text using T5.
        :param text: The input text to summarize.
        :param custom_prompt: Custom prompt to tweak the summary.
        :param max_length: Maximum length of the summary.
        :param min_length: Minimum length of the summary.
        :return: Summarized text.
        """
        input_text = f"summarize: {custom_prompt or ''} " + text
        inputs = self.t5_tokenizer.encode(input_text, return_tensors="pt", truncation=True, max_length=512).to(self.device)
        summary_ids = self.t5_model.generate(
            inputs,
            max_length=max_length,
            min_length=min_length,
            length_penalty=1.0,
            num_beams=6,
            early_stopping=True
        )
        return self.t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True).strip()

    def generate_ground_truth(self, text: str, max_length: int = 150, min_length: int = 100) -> str:
        """
        Generate the ground truth summary using BART.
        :param text: The input text to summarize.
        :param max_length: Maximum length of the summary.
        :param min_length: Minimum length of the summary.
        :return: Ground truth summary.
        """
        inputs = self.bart_tokenizer.encode(text, return_tensors="pt", truncation=True, max_length=512).to(self.device)
        summary_ids = self.bart_model.generate(
            inputs,
            max_length=max_length,
            min_length=min_length,
            length_penalty=1.0,
            num_beams=6,
            early_stopping=True
        )
        return self.bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True).strip()

    def evaluate(self, generated_summary: str, ground_truth: str):
        """
        Evaluate the generated summary using SacreBLEU, BLEU, and METEOR scores.
        :param generated_summary: The summary generated by the T5 model.
        :param ground_truth: The ground truth summary generated by BART.
        :return: A dictionary with SacreBLEU, BLEU, and METEOR scores.
        """
        references = [[ground_truth]]
        predictions = [generated_summary]

        # Calculate SacreBLEU, BLEU, and METEOR scores
        sacrebleu_score = sacrebleu.compute(predictions=predictions, references=references)['score']
        bleu_score = bleu.compute(predictions=predictions, references=references)['bleu']
        meteor_score = meteor.compute(predictions=predictions, references=references)['meteor']

        return {
            'sacrebleu': sacrebleu_score,
            'bleu': bleu_score,
            'meteor': meteor_score
        }

def setup_logging():
    """
    Setup logging configuration to track application behavior.
    """
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler("summarization_evaluator.log"),
            logging.StreamHandler()
        ]
    )

def main():
    """
    Main function to execute summarization and evaluation using T5, BART, and various metrics.
    """
    setup_logging()

    # Example text input
    article_text = """
China’s economy picked up pace in the first quarter as Beijing’s plan to boost growth by pouring money into factories began to show results.
But that approach is leading to a lopsided recovery and stoking trade tensions overseas, with Western governments and some big emerging economies crying foul over a growing wave of cheap Chinese imports they say threatens domestic jobs and industries.
With familiar signs of weakness in consumption and real ­estate in the first three months of the year, many economists say Beijing still isn’t doing enough to support households and nurture a more balanced recovery.
And the loss of some momentum in March compared with the preceding two months reinforced expectations that further stimulus will be needed to ensure that the government meets its growth target of 5 per cent for the year.
China said its economy grew 5.3 per cent in the first quarter compared with the same three months a year earlier, a faster pace than the 5.2 per cent year-over-year growth rate that the country notched in the final quarter of 2023, China’s National Bureau of Statistics said on Tuesday.
The pick-up was propelled by a rise in industrial production and swelling investment in factories. After a challenging few years, Chinese officials are steering activity and investment towards manufacturing and exports to compensate for domestic consumers’ reluctance to spend and a continuing crunch in the property market.
Beijing is also seeking to stake out a commanding lead in newer hi-tech industries such as electric vehicles and renewable energy equipment – sectors it counts among the “new productive ­forces” it wants to harness to fuel the next stage of China’s economic ascendancy.
But Beijing’s strategy is raising hackles around the world as governments baulk at the risk to jobs and industries from a potential rerun of the “China shock” of the early 2000s, when a torrent of Chinese imports hit low-tech manufacturing in the US, costing the country an estimated two million jobs.
The US and Europe are pushing back against Chinese EVs, solar panels and wind turbines, new industries that they are also seeking to dominate. Emerging economies are feeling the heat from China’s manufacturing glut too, with Brazil, India and Mexico among those investigating whether Chinese products such as steel and ceramics are being dumped on their markets at unfairly low prices.
China says its companies are competing fairly and has criticised such moves as protectionism. The International Monetary Fund and others warn that these mounting tensions over trade could lead to the global economy fracturing, with blocs of countries allied around the US and China, respectively, and broader trade impeded.
Tuesday’s data laid out in detail the fruits of Beijing’s strategy, with industrial production rising 6.1 per cent from a year earlier in the first quarter, propelling overall growth. Investment in manufacturing rose 9.9 per cent.
But there were also signs of the strategy’s limits. There was a growing mismatch between ballooning supply and lacklustre demand, with China’s factories reporting a fall in the amount of available production capacity they are using. Overall capacity utilisation fell 0.7 percentage points in the first quarter to 73.6 per cent, with steeper drops in industries including cars and electrical machinery. In February, inventories of finished products were 2.4 per cent larger than a year earlier. “It is a positive omen for the world economy that China seems to be getting past a rough patch. However, these data will not ­assuage concerns that a production-led recovery and weak consumption demand could lead China to aggressively push exports to keep its recovery going,” said Eswar Prasad, professor of trade policy and economics at Cornell University and a former head of the IMF’s China division.
"""
    try:
        # Initialize the summarizer and evaluator
        evaluator = SummarizationEvaluator(t5_model_name="t5-large", bart_model_name="facebook/bart-large-cnn")

        # Generate T5 summary
        generated_summary = evaluator.summarize_t5(article_text, custom_prompt="Summarize from the perspective of a risk manager")

        # Generate BART ground truth
        ground_truth_summary = evaluator.generate_ground_truth(article_text)

        # Evaluate using SacreBLEU, BLEU, and METEOR
        scores = evaluator.evaluate(generated_summary, ground_truth_summary)

        # Output the results
        print("Generated Summary:")
        print(generated_summary)
        print("\nGround Truth Summary (BART):")
        print(ground_truth_summary)
        print("\nScores:")
        print(f"SacreBLEU: {scores['sacrebleu']}")
        print(f"BLEU: {scores['bleu']}")
        print(f"METEOR: {scores['meteor']}")

    except Exception as e:
        logging.error(f"Error during summarization or evaluation: {e}")

if __name__ == "__main__":
    main()
